filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
print(hm_data2)
#datatable(hm_data)
#names(hm_data)
datatable(hm_data1)
datatable(hm_data2)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create bigrams using the text data
hm_bigrams <- hm_data1 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts <- hm_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
#Create bigrams using the text data
hm_bigrams2 <- hm_data2 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts2 <- hm_bigrams2 %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age>=21 & age<=37)
# tech_related<-read_csv("Technology_Entertainment.csv")
# people_related<-read_csv("people-dict.csv")
#print(millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a bag of words using the text data
bag_of_words3 <-non_millenials %>%
unnest_tokens(word3, text3)
### Combine both the data sets and keep the required columns for analysis
#We select a subset of the data that satisfies specific row conditions.
hm_data1 <- hm_data1 %>%
inner_join(demo_data1, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data1$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
# Step 1 - Load the processed text data along with demographic information on contributors
# We use the processed data for our analysis and combine it with the demographic information available.
hm_data1 <- read_csv("../output/processed_moments.csv")
hm_data2 <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data1 <- read_csv(urlfile)
demo_data2 <- read_csv(urlfile)
#print(hm_data)
### Combine both the data sets and keep the required columns for analysis
#We select a subset of the data that satisfies specific row conditions.
hm_data1 <- hm_data1 %>%
inner_join(demo_data1, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data1$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
dim(hm_data1)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(wordcloud)
# Step 1 - Load the processed text data along with demographic information on contributors
# We use the processed data for our analysis and combine it with the demographic information available.
hm_data1 <- read_csv("../output/processed_moments.csv")
hm_data2 <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data1 <- read_csv(urlfile)
demo_data2 <- read_csv(urlfile)
#print(hm_data)
### Combine both the data sets and keep the required columns for analysis
#We select a subset of the data that satisfies specific row conditions.
hm_data1 <- hm_data1 %>%
inner_join(demo_data1, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data1$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
dim(hm_data1)
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
print(hm_data2)
#datatable(hm_data)
#names(hm_data)
datatable(hm_data1)
datatable(hm_data2)
#Create bigrams using the text data
hm_bigrams <- hm_data1 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts <- hm_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
#Create bigrams using the text data
hm_bigrams2 <- hm_data2 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts2 <- hm_bigrams2 %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age>=21 & age<=37)
# tech_related<-read_csv("Technology_Entertainment.csv")
# people_related<-read_csv("people-dict.csv")
#print(millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a bag of words using the text data
bag_of_words3 <-non_millenials %>%
unnest_tokens(word3, text3)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age>=21 & age<=37)
# tech_related<-read_csv("Technology_Entertainment.csv")
# people_related<-read_csv("people-dict.csv")
print(millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<21 & age>37)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<=22 & age>=38)
print(non_millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<=20 & age>=38)
print(non_millenials)
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid2") %>%
select(wid2,
original_hm2,
gender2,
marital2,
parenthood2,
reflection_period2,
age2,
country2,
ground_truth_category2,
text2) %>%
mutate(count = sapply(hm_data2$text2, wordcount2)) %>%
filter(gender2 %in% c("m", "f")) %>%
filter(marital2 %in% c("single", "married")) %>%
filter(parenthood2 %in% c("n", "y")) %>%
filter(reflection_period2 %in% c("24h", "3m")) %>%
mutate(reflection_period2 = fct_recode(reflection_period2,
months_32 = "3m", hours_242 = "24h"))
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm2,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(wordcloud)
# Step 1 - Load the processed text data along with demographic information on contributors
# We use the processed data for our analysis and combine it with the demographic information available.
hm_data1 <- read_csv("../output/processed_moments.csv")
hm_data2 <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data1 <- read_csv(urlfile)
demo_data2 <- read_csv(urlfile)
#print(hm_data)
### Combine both the data sets and keep the required columns for analysis
#We select a subset of the data that satisfies specific row conditions.
hm_data1 <- hm_data1 %>%
inner_join(demo_data1, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data1$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
dim(hm_data1)
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm2,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
# Step 1 - Load the processed text data along with demographic information on contributors
# We use the processed data for our analysis and combine it with the demographic information available.
hm_data1 <- read_csv("../output/processed_moments.csv")
hm_data2 <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data1 <- read_csv(urlfile)
demo_data2 <- read_csv(urlfile)
#print(hm_data)
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm2,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
print(hm_data2)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age<=21 & age>=37)
library(tm)
library(tidytext)
library(tidyverse)
library(DT)
library(tidyverse)
library(tidytext)
library(DT)
library(scales)
library(wordcloud2)
library(gridExtra)
library(ngram)
library(shiny)
library(wordcloud)
# Step 1 - Load the processed text data along with demographic information on contributors
# We use the processed data for our analysis and combine it with the demographic information available.
hm_data1 <- read_csv("../output/processed_moments.csv")
hm_data2 <- read_csv("../output/processed_moments.csv")
urlfile<-'https://raw.githubusercontent.com/rit-public/HappyDB/master/happydb/data/demographic.csv'
demo_data1 <- read_csv(urlfile)
demo_data2 <- read_csv(urlfile)
#print(hm_data)
### Combine both the data sets and keep the required columns for analysis
#We select a subset of the data that satisfies specific row conditions.
hm_data1 <- hm_data1 %>%
inner_join(demo_data1, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data1$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
dim(hm_data1)
hm_data2 <- hm_data2 %>%
inner_join(demo_data2, by = "wid") %>%
select(wid,
original_hm,
gender,
marital,
parenthood,
reflection_period,
age,
country,
ground_truth_category,
text) %>%
mutate(count = sapply(hm_data2$text, wordcount)) %>%
filter(gender %in% c("m", "f")) %>%
filter(marital %in% c("single", "married")) %>%
filter(parenthood %in% c("n", "y")) %>%
filter(reflection_period %in% c("24h", "3m")) %>%
mutate(reflection_period = fct_recode(reflection_period,
months_3 = "3m", hours_24 = "24h"))
print(hm_data2)
#datatable(hm_data)
#names(hm_data)
datatable(hm_data1)
datatable(hm_data2)
#Create bigrams using the text data
hm_bigrams <- hm_data1 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts <- hm_bigrams %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
#Create bigrams using the text data
hm_bigrams2 <- hm_data2 %>%
filter(count != 1) %>%
unnest_tokens(bigram, text, token = "ngrams", n = 2)
bigram_counts2 <- hm_bigrams2 %>%
separate(bigram, c("word1", "word2"), sep = " ") %>%
count(word1, word2, sort = TRUE)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age<=21 & age>=37)
# tech_related<-read_csv("Technology_Entertainment.csv")
# people_related<-read_csv("people-dict.csv")
print(millenials)
#Create a data set with non-millenials
non_millenials<-hm_data2 %>%
filter(age<=20 & age>=38)
print(non_millenials)
#Create a bag of words using the text data
bag_of_words3 <-non_millenials %>%
unnest_tokens(word3, text3)
### Create a data set with milennials only
millenials<-hm_data1 %>%
filter(age>=21 & age<=37)
# tech_related<-read_csv("Technology_Entertainment.csv")
# people_related<-read_csv("people-dict.csv")
print(millenials)
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
runApp()
